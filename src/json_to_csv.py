"""
Script to create csvs from a set of generated mockaroo jsons. See chord_metadata_service/mohpackets/data
https://github.com/CanDIG/katsu/tree/develop/chord_metadata_service/mohpackets/data for more information on how to
generate the data. Shouldn't need to be regenerated unless the underlying MoH model changes significantly.
"""

import os
import json
import pandas as pd
import argparse
from pathlib import Path


def sort_key(file_name):
    """Sorting key to ensure jsons are processed in the correct order."""
    sort_key = {'Donor.json': 0, 'PrimaryDiagnosis.json': 1, 'Treatment.json': 2, 'Specimen.json': 3,
                'SampleRegistration.json': 4, 'Followup.json': 5, 'SystemicTherapy.json': 6,
                'Surgery.json': 7, 'Radiation.json': 8, 'Biomarker.json': 9,
                'Comorbidity.json': 10, 'Exposure.json': 11, 'Program.json': 12}
    return sort_key[file_name]


def convert_to_csv(size, input_path):
    # Get the absolute path to the synthetic data folder
    repo_dir = os.path.dirname(os.path.dirname(__file__))
    synthetic_data_folder = input_path
    output_dir = os.path.join(repo_dir, f"{size}_dataset_csv/raw_data")
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Iterate through all JSON files in the synthetic_data_folder
    print(f"Processing json files from {synthetic_data_folder}...")

    file_list = list(os.listdir(synthetic_data_folder))
    file_list = sorted(file_list, key=sort_key)
    for filename in file_list:
        if filename.endswith('.json') and not filename.startswith("Program"):
            print(filename)
            json_file_path = os.path.join(synthetic_data_folder, filename)
            with open(json_file_path, 'r') as f:
                data = json.load(f)
                df = pd.DataFrame(data)
                for column in df.columns:
                    if df[column].apply(lambda x: isinstance(x, list)).any():
                        df[column] = df[column].apply(lambda x: '|'.join(x) if isinstance(x, list) else x)
                # Save the DataFrame to a CSV file in the output directory
                output_csv_file = os.path.join(output_dir, f"{filename.replace('.json', '.csv')}")
                df.to_csv(output_csv_file, index=False)
    print("All done!")


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--size',
        type=str,
        default='s',
        choices=['s', 'm', 'l'],
        help="Size of the synthetic dataset to convert, options: 's' for small, 'm' for medium, 'l' for large (default: small)"
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help="Path to generated json files. Assumes a folder structure such as 'small_dataset/synthetic_data/*.json' such as generated by katsu data_factory.py script."
    )
    args = parser.parse_args()
    return args


def main():
    args = parse_args()
    size_mapping = {'s': 'small', 'm': 'medium', 'l': 'large'}
    convert_to_csv(size_mapping[args.size], f"{args.input}/{size_mapping[args.size]}_dataset/synthetic_data")


if __name__ == "__main__":
    main()
