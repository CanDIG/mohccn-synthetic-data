"""
Script to create csvs from a set of generated mockaroo jsons. See chord_metadata_service/mohpackets/data
https://github.com/CanDIG/katsu/tree/develop/chord_metadata_service/mohpackets/data for more information on how to
generate the data. Shouldn't need to be regenerated unless the underlying MoH model changes significantly.
"""

import os
import json
import pandas as pd
import argparse
from pathlib import Path
import extra_donors
import post_processing


def convert_to_csv(size, input_path):
    # Get the absolute path to the synthetic data folder
    repo_dir = os.path.dirname(os.path.dirname(__file__))
    synthetic_data_folder = input_path
    output_dir = os.path.join(repo_dir, f"{size}_dataset_csv/raw_data")
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Iterate through all JSON files in the synthetic_data_folder
    print(f"Processing json files from {synthetic_data_folder}...")
    for filename in os.listdir(synthetic_data_folder):
        if filename.endswith('.json') and not filename.startswith("Program"):
            print(filename)
            json_file_path = os.path.join(synthetic_data_folder, filename)
            with open(json_file_path, 'r') as f:
                data = json.load(f)
                extra_objects = extra_donors.add_objects(filename)
                if extra_objects:
                    data.extend(extra_objects)
                df = pd.DataFrame(data)
                df = post_processing.process_objects(filename, df)
                # Concatenate values with pipe for all columns with list-type values
                for column in df.columns:
                    if df[column].apply(lambda x: isinstance(x, list)).any():
                        df[column] = df[column].apply(lambda x: '|'.join(x) if isinstance(x, list) else x)

                # Save the DataFrame to a CSV file in the output directory
                output_csv_file = os.path.join(output_dir, f"{filename.replace('.json', '.csv')}")
                df.to_csv(output_csv_file, index=False)
    print("All done!")


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--size',
        type=str,
        default='s',
        choices=['s', 'm', 'l'],
        help="Size of the synthetic dataset to convert, options: 's' for small, 'm' for medium, 'l' for large (default: small)"
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help="Path to generated mockaroo files. Assumes a folder structure such as 'mockaroo_data/small_dataset/synthetic_data/*.json' such as generated by katsu data_converter.py script."
    )
    args = parser.parse_args()
    return args


def main():
    args = parse_args()
    size_mapping = {'s': 'small', 'm': 'medium', 'l': 'large'}
    convert_to_csv(size_mapping[args.size], f"{args.input}/{size_mapping[args.size]}_dataset/synthetic_data")


if __name__ == "__main__":
    main()
